\documentclass[article,shortnames]{jss}

\usepackage{amsmath,rotating}
\usepackage{color}
\definecolor{BrickRed}{rgb}{1,0,0}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% declarations for jss.cls %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% almost as usual
\author{Brandon Whitcher\\GlaxoSmithKline \And 
        Volker J. Schmid\\Ludwig-Maximilians Universit\"at M\"unchen \AND
        Andrew Thornton\\Cardiff University}
\title{Working with the {DICOM} and {NIfTI} Data Standards in \proglang{R}}

%% for pretty printing and a nice hypersummary also set:
\Plainauthor{Brandon Whitcher, Volker J. Schmid, Andrew Thornton} %% comma-separated
\Plaintitle{Working with the {DICOM} and {NIfTI} Data Standards in R} %% without formatting
\Shorttitle{{DICOM} and {NIfTI} in R} %% a short title (if necessary)

%% an abstract and keywords
\Abstract{

Two packages (\pkg{oro.dicom} and \pkg{oro.nifti}) are provided for
the interaction with and manipulation of medical imaging data that
conform to the DICOM standard or ANALYZE/NIfTI formats.  DICOM data,
from a single file or single directory or directory tree, may be
uploaded into \proglang{R} using basic data structures: a data frame
for the header information and a matrix for the image data.  A list
structure is used to organize multiple DICOM files.  The \proglang{S}4
class framework is used to develop basic ANALYZE and NIfTI classes,
where NIfTI extensions may be used to extend the fixed-byte NIfTI
header.  One example of this, that has been implemented, is an
\proglang{XML}-based ``audit trail'' that tracks the history of
operations applied to a dataset.  The conversion from DICOM to
ANALYZE/NIfTI is straightforward using the capabilities of both
packages.  The \proglang{S}4 classes have been developed to provide a
user-friendly interface to the ANALYZE/NIfTI data formats; allowing
easy data input, data output, image processing and visualization.

}
\Keywords{export, imaging, import, medical, visualization}
\Plainkeywords{export, imaging, import, medical, visualization} %% without formatting
%% at least one keyword must be supplied

%% publication information
%% NOTE: Typically, this can be left commented and will be filled out by the technical editor
%% \Volume{13}
%% \Issue{9}
%% \Month{September}
%% \Year{2004}
%% \Submitdate{2004-09-29}
%% \Acceptdate{2004-09-29}

%% The address of (at least) one author should be given
%% in the following format:
\Address{
  Brandon Whitcher\\
  GlaxoSmithKline Clinical Imaging Centre\\
  Hammersmith Hospital\\
  London W12 0HS, United Kingdom\\
  E-mail: \email{bjw34032@users.sourceforge.net}\\
  URL: \url{http://rigorousanalytics.blogspot.com}\\
  
  Volker J. Schmid\\
  Bioimaging group\\
  Department of Statistics\\
  Ludwig-Maximilians-Universit\"at M\"unchen\\
  80539 M\"unchen, Germany\\
  E-mail: \email{volker.schmid@lmu.de}\\
  URL: \url{http://volkerschmid.de}\\
  
  Andrew Thornton\\
  Cardiff University School of Medicine\\
  Heath Park\\
  Cardiff CF14 4XN, United Kingdom\\
  E-mail: \email{art27@cantab.net}\\
  URL: \url{http://}\\
}
%% It is also possible to add a telephone and fax number
%% before the e-mail in the following format:
%% Telephone: +43/1/31336-5053
%% Fax: +43/1/31336-734

%% for those who use Sweave please include the following line (with % symbols):
%% need no \usepackage{Sweave.sty}

%% end of declarations %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

<<preliminaries,echo=FALSE,results=hide>>=
library("oro.dicom")
library("bitops")
library("XML")
library("splines")
library("oro.nifti")
options(width=75)
options(prompt="R> ")
@

\begin{document}

%% include your article here, just as usual
%% Note that you should use the \pkg{}, \proglang{} and \code{} commands.

\section{Introduction}

Medical imaging is well established in both the clinical and research
areas with numerous equipment manufacturers supplying a wide variety
of modalities.  The DICOM (Digital Imaging and Communications in
Medicine; \url{http://medical.nema.org}) standard was developed from
earlier standards and released in 1993. It is the data format for
clinical imaging equipment and a variety of other devices whose
complete specification is beyond the scope of this paper.  All major
manufacturers of medical imaging equipment (e.g., GE, Siemens,
Philips) have so-called DICOM conformance statements that explicitly
state how their hardware implements DICOM.  The DICOM standard
provides interoperability across hardware, but was not designed to
facilitate efficient data manipulation and image processing.  Hence,
additional data formats have been developed over the years to
accommodate data analysis and image processing.

The ANALYZE format was developed at the Mayo Clinic (in the 1990s) to
store multidimensional biomedical images.  It is fundamentally
different from the DICOM standard since it groups all images from a
single acquisition (typically three- or four-dimensional) into a pair
of binary files, one containing header information and one containing
the image information.  The DICOM standard groups the header and image
information, typically a single two-dimensional image, into a single
file.  Hence, a single acquisition will contain multiple DICOM files
but only a pair of ANALYZE files.

The NIfTI format was developed in the early 2000s by the DFWG (Data
Format Working Group) in an effort to improve upon the ANALYZE format.
The resulting NIfTI-1 format adheres to the basic header/image
combination from the ANALYZE format, but allows the pair of files to
be combined into a single file and re-defines the header fields.
In addition, NIfTI extension allow to store any additional information.

The material presented here provides users with a method of
interacting with DICOM, ANALYZE and NIfTI files in \proglang{R}
\citep{R}.  Real-world datasets, that are publicly available, are used
to illustrate the basic functionality of the two packages:
\pkg{oro.dicom} and \pkg{oro.nifti}.  Major features include data
input/output, visualization and conversion from DICOM to
ANALYZE/NIfTI.  \textcolor{BrickRed}{These packages should appeal not
  only to other \proglang{R} package developers, but also to
  scientists who want to manipulate medical imaging data using
  \proglang{R} without writing and validating basic data input/output
  functionality.  Packages already available on CRAN that utilize
  \pkg{oro.dicom} and \pkg{oro.nifti} include \pkg{cudaBayesreg}
  \citep{cudaBayesreg}, \pkg{dcemriS4} \citep{dcemriS4} and
  \pkg{dpmixsim} \citep{dpmixsim}.}

\section[oro.dicom: DICOM data input/output in R]{\pkg{oro.dicom}: DICOM data input/output in \proglang{R}}

% The industry standard format, for data acquired using a clinical
% imaging device, is DICOM (Digital Imaging and Communications in
% Medicine).
The DICOM ``standard'' for data acquired using a clinical imaging
device is very broad and complex.  Roughly speaking each
DICOM-compliant file is a collection of fields organized into two
\textcolor{BrickRed}{two-byte} sequences (group,element) that are
represented as hexadecimal numbers and form a tag.  The
(group,element) combination establishes what type of information is
forthcoming in the file.  There is no fixed number of bytes for a
DICOM header.  The final (group,element) tag should be the ``pixel
data'' tag (7FE0,0010), such that all subsequent information is
related to the image(s).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[tpb]
  \begin{center}
    \begin{tabular}{llrr}
      \hline
      \textbf{Code} & \textbf{Name} & \textbf{Bytes} & \textbf{Fixed}\\
      \hline\\
      AE & ApplicationEntity & 16 & 0\\
      AS & AgeString & 4 & 1\\
      AT & AttributeTag & 4 & 1\\
      CS & CodeString & 16 & 0\\
      DA & Date & 8 & 1\\
      DS & DecimalString & 16 & 0\\
      DT & DateTime & 26 & 0\\
      FL & FloatingPointSingle & 4 & 1\\
      FD & FloatingPointDouble & 8 & 1\\
      IS & IntegerString & 12 & 0\\
      LO & LongStrong & 64 & 0\\
      LT & LongText & 10240 & 0\\
      OB & OtherByteString & 0 & 0\\
      OW & OtherWordString & 0 & 0\\
      PN & PersonName & 64 & 0\\
      SH & ShortString & 16 & 0\\
      SL & SignedLong & 4 & 1\\
      SQ & SequenceOfItems & 0 & 0\\
      SS & SignedShort & 2 & 1\\
      ST & ShortText & 1024 & 0\\
      TM & Time & 16 & 0\\
      UI & UniqueIdentifierUID & 64 & 0\\
      UL & UnsignedLong & 4 & 1\\
      UN & Unknown & 0 & 0\\
      US & UnsignedShort & 2 & 1\\
      UT & UnlimitedText & 0 & 0\\
      \hline
    \end{tabular}
  \end{center}
  \caption{Value representations in the DICOM standard.
    \textcolor{BrickRed}{A value of zero bytes may be interpreted as
      having an unknown or unlimited number of bytes associated with
      the VR.}}
  \label{tab:VR}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

All attributes in the DICOM standard require different data types for
correct representation.  These are known as value representations
(VRs) in DICOM, \textcolor{BrickRed}{which may be encoded explicitly
  or implicitly.  There are 27 explicit VRs defined in the DICOM
  standard, and provided in Table~\ref{tab:VR}}.  Detailed
explanations of these data types are provided in the Section~6.2
(part~5) of the DICOM standard (\url{http://medical.nema.org}).  The
first column provides the two-character string that is present in each
entry of the header field and the second column provides a descriptive
name for the abbreviated code.  The third column provides the maximum
length of the data associated with the VR (in bytes), where a length
of zero bytes may be interpreted as having an unknown or unlimited
number of bytes associated with the VR.  The fourth column is not used
in the current implementation of the \pkg{oro.dicom} package.
Internal functions have been written to manipulate each of the value
representations and are beyond the scope of this article.  The
functions \code{str2date} and \code{str2time} are useful for
converting from the DICOM \code{Datetime} and \code{Time} value
representations to \proglang{R} date and time objects, respectively.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[tbp]
\begin{verbatim}
Data element with explicit VR of OB, OF, OW, SQ, UT or UN:

+-----------------------------------------------------------+
|  0 |  1 |  2 |  3 |  4 |  5 |  6 |  7 |  8 |  9 | 10 | 11 |
+----+----+----+----+----+----+----+----+----+----+----+----+
|<Group-->|<Element>|<VR----->|<0x0000->|<Length----------->|<Value->

Data element with explicit VR other than as shown above:

+---------------------------------------+
|  0 |  1 |  2 |  3 |  4 |  5 |  6 |  7 |
+----+----+----+----+----+----+----+----+
|<Group-->|<Element>|<VR----->|<Length->|<Value->

Data element with implicit VR:

+---------------------------------------+
|  0 |  1 |  2 |  3 |  4 |  5 |  6 |  7 |
+----+----+----+----+----+----+----+----+
|<Group-->|<Element>|<Length----------->|<Value->
\end{verbatim}
\caption{Byte ordering for a single (group,element) tag in the DICOM
  standard.  Explicit VRs store the VR as text characters in two
  bytes.  More information is provided in Section~7, Part 3.5-2009 of
  the DICOM standard (\url{http://medical.nema.org}).}
\label{fig:group-element}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The DICOM header}
\label{sec:dicom-header}

Accessing the information stored in a single DICOM file is provided
using the \code{dicomInfo} function.  The basic structure of a DICOM
file is summarized in Figure~\ref{fig:group-element}, for both
explicit and implicit value representations.  The first two bytes
represent the \code{group} tag and the second two bytes represent the
\code{element} tag, regardless of the type of VR.  The third set of
two bytes contains the characters of the VR on which a decision about
being implicit or explicit is made.  Explicit VRs of type \code{(OB,
  OF, OW, SQ, UT, UN)} skip bytes six and seven (counting from zero),
convert the next four bytes into an integer \code{length} and read
\code{length} number of objects from the DICOM file.  All other
explicit VRs follow a slightly different path where bytes six and
seven (counting from zero) provide an integer \code{length} and all
remaining bytes are read in as the \code{value}.  If the character
string in bytes four and five do not correspond to a known VR
(Figure~\ref{fig:group-element}), then the
(\code{group},\code{element}) tag is declared to be implicit, the
\code{length} is taken from bytes four through seven and all remaining
bytes contribute to the \code{value}.

The basic structure of the resulting object is a list with two
elements: the DICOM header (\code{hdr}) and the DICOM image
(\code{img}).  The header information is organized in a data frame
with six columns and an unknown number of rows depending on the input
parameters.

<<DICOM Abdo 01>>=
fname <- system.file(file.path("dcm", "Abdo.dcm"), package="oro.dicom")
abdo <- dicomInfo(fname)
names(abdo)
abdo$hdr[1:5,]
abdo$hdr[nrow(abdo$hdr)-4:0,]
@ 

The ordering of the rows is identical to the ordering in the original
DICOM file.  Hence, the first five tags in the DICOM header of
\code{Abdo.dcm} are: \code{GroupLength},
\code{FileMetaInformationVersion}, \code{MediaStorageSOPClassUID},
\code{MediaStorageSOPInstanceUID} and \code{TransferSyntaxUID}.  The
last five tags in the DICOM header are also shown, with the very last
tag indicating the start of the image data for that file and the
number of bytes (131072) involved.  When additional tags in the DICOM
header information are queried (via \code{extractHeader})

<<DICOM Abdo 02>>=
extractHeader(abdo$hdr, "BitsAllocated")
extractHeader(abdo$hdr, "Rows")
extractHeader(abdo$hdr, "Columns")
@ 

it is clear that the data are consistent with the header information
in terms of the number of bytes ($256\times256\times(16/8)=131072$).

The first five columns are taken directly from the DICOM header
information (\code{group}, \code{element}, \code{code}, \code{length}
and \code{value}) or inferred from that information (\code{name}).
Note, the (\code{group},\code{element}) values are stored as character
strings even though they are hexadecimal numbers.  All aspects of the
data frame may be interrogated in \proglang{R} in order to extract
relevant information from the DICOM header; e.g.,
\code{"BitsAllocated"} as above.  The \code{sequence} column is used
to keep track of tags that are embedded in a fixed-length
SequenceItems tag or between a SequenceItem-SequenceDelimitationItem
pair.

When multiple DICOM files are located in a single directory, or spread
across multiple directories, one may use the function
\code{dicomSeparate} (applied here to the directory \code{hk-40}).

<<DICOM HK40 01>>=
fname <- system.file("hk-40", package="oro.dicom")
hk40 <- dicomSeparate(fname, verbose=TRUE, counter=10)
unlist(lapply(hk40, length))
@ 

The object associated with \code{dicomSeparate} is now a nested set of
lists, where the \code{hdr} element is a list of data frames and the
\code{img} element is a list of matrices.  These two lists are
associated in a pairwise sense; i.e., \code{hdr[[1]]} is the header
information for the image \code{img[[1]]}.  Default parameters
\code{recursive = TRUE} and \code{pixelData = TRUE} (which is actually
an input parameter for \code{dicomInfo}) allow the user to search down
all possible sub-directories and upload the image in addition to the
header information, respectively.  Also, by default all files are
treated as DICOM files unless the \code{exclude} parameter is set to
the unwanted file extension; e.g., \code{exclude = "xml"}.

The list of DICOM header information across multiple files may be
converted to a single data frame using \code{dicomTable}, and written
to disc for further analysis; e.g., using \code{write.csv}.

<<DICOM HK40 02>>=
hk40.info <- dicomTable(hk40$hdr)
write.csv(hk40.info, file="hk40_header.csv")
sliceloc.col <- which(hk40$hdr[[1]]$name == "SliceLocation") 
sliceLocation <- as.numeric(hk40.info[, sliceloc.col])
sliceLocation[1:5]
diff(sliceLocation[1:5])
unique(extractHeader(hk40$hdr, "SliceThickness"))
@ 

The tag \code{SliceLocation} is extracted from the DICOM header
information (at the first element in the list) and processed using the
\code{diff} function, and should agree with the \code{SliceThickness}
tag.  Single DICOM fields may also be extracted from the list of DICOM
header information that contain attributes that are crucial for
further image processing; e.g., extracting relevant MR sequences or
acquisition timings.

<<DICOM HK40 03>>=
extractHeader(hk40$hdr, "SliceLocation")[1:5]
modality <- extractHeader(hk40$hdr, "Modality", numeric=FALSE)
matchHeader(modality, "mr")[1:5]
(seriesTime <- extractHeader(hk40$hdr, "SeriesTime", numeric=FALSE))
str2time(seriesTime[1:5])
@ 

\subsection{The DICOM image}

Most DICOM files involve a single slice from an acquisition -- the
image.  A notable exception is the Siemens MOSAIC format (addressed in
Section~\ref{sec:mosaic}).  \textcolor{BrickRed}{The \pkg{oro.dicom}
  package assumes the image is stored as a flat file of two-byte
  integers without compression.  A variety of additional image formats
  are possible within the DICOM standard; for example, RGB-colorized,
  JPEG, JPEG Lossless, JPEG 2000 and run-length encoding (RLE)}.
Going back to the \code{Abdo.dcm} example, the image is accessed via

<<abdo-png,echo=FALSE,results=hide>>=
png(filename="dicom_abdo.png", width=2*480, height=2*480, bg="black")
par(mar=rep(0,4))
@ 
<<abdo-image>>=
image(t(abdo$img), col=grey(0:64/64), axes=FALSE, xlab="", ylab="")
@ 
<<abdo-dev.off,echo=FALSE,results=hide>>=
dev.off()
#par(mar=c(5,4,4,2)+0.1)
@ 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[tbp]
  \centering
  \includegraphics*[width=0.6\textwidth]{dicom_abdo.png}
  \caption{Coronal slice of the abdomen viewed in
    \textit{neurological} convention (left is right and right is
    left).}
  \label{fig:dicom_abdo}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

where the transpose operation is necessary for proper visualization of
the image.  Figure~\ref{fig:dicom_abdo} displays a coronal slice
through the abdomen from an MRI acquisition.  All information from the
original data acquisition should accompany the image through the DICOM
header, and this information is utilized as much as possible by
\pkg{oro.dicom} to simplify the manipulation of DICOM data.  As
previously shown, this information is easily available to the user by
matching DICOM header fields with valid strings.  Note, the function
\code{extractHeader} assumes the output should be coerced via
\code{as.numeric} but this may be disabled setting the input parameter
\code{numeric=FALSE}.

<<DICOM Abdo 03>>=
extractHeader(abdo$hdr, "Manufacturer", numeric=FALSE)
extractHeader(abdo$hdr, "RepetitionTime")
extractHeader(abdo$hdr, "EchoTime")
@ 

The basic DICOM file structure does not encourage the analysis of
multi-dimensional imaging data (e.g., 3D or~4D) commonly acquired on
clinical scanners.  Hence, the \pkg{oro.dicom} package has been
developed to access DICOM files and facilitate their conversion to the
NIfTI or ANALYZE formats.  The conversion process requires the
\pkg{oro.nifti} package and will be outlined in
Section~\ref{sec:dicom2nifti}.

\subsubsection{Siemens MOSAIC format}
\label{sec:mosaic}

Siemens multi-slice EPI (echo planar imaging) data may be collected as
a ``mosaic'' image; i.e., all slices acquired in a single TR
(repetition time) frame of a dynamic run are stored in a single DICOM
file.  The images are stored in an $M{\times}N$ array of images.  The
function \code{create3D} will try to guess the number of images
embedded within the single DICOM file using the
\code{AcquisitionMatrix} field.  If this doesn't work, one may enter
the $(M,N)$ doublet explicitly.

<<DICOM Siemens 01>>=
fname <- system.file(file.path("dcm", "MR-sonata-3D-as-Tile.dcm"),
                     package="oro.dicom")
dcm <- dicomInfo(fname)
dim(dcm$img)
dcmImage <- create3D(dcm, mosaic=TRUE)
dim(dcmImage)
@ 

<<DICOM Siemens 02,echo=FALSE,results=hide>>=
dcmNifti <- dicom2nifti(dcm, mosaic=TRUE)
png(filename="dcmImage.png", width=2*480, height=2*480, bg="black")
image(t(dcm$img), col=grey(0:64/64), axes=FALSE, xlab="", ylab="")
dev.off()
png(filename="dcmNifti.png", width=2*480, height=2*480, bg="black")
image(dcmNifti)
dev.off()
@ 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[tbp]
  \begin{center}
    \begin{tabular}{cc}
      \includegraphics*[width=0.45\textwidth]{dcmImage.png} & 
      \includegraphics*[width=0.45\textwidth]{dcmNifti.png}\\
      \textbf{(a)} & \textbf{(b)}
    \end{tabular}
  \end{center}
  \caption{\textbf{(a)} Single MOSAIC image as read in from
    \code{dicomInfo}.  \textbf{(b)} Lightbox display of
    three-dimensional array of images after processing via
    \code{create3D}.}
  \label{fig:mosaic}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Figure~\ref{fig:mosaic}a is taken from the raw DICOM file, in mosaic
format, and displayed with the default margins in \proglang{R}.
Figure~\ref{fig:mosaic}b is displayed after re-organizing the original
DICOM file into a three-dimensional array (it was also converted to
the NIfTI format for ease of visualization using the overloaded
\code{image} function in \pkg{oro.nifti}).

\section[oro.nifti: NIfTI-1 data input/output in R]{\pkg{oro.nifti}: NIfTI-1 data input/output in \proglang{R}}

Although the industry standard for medical imaging data is DICOM,
another format has come to be heavily used in the image analysis
community.  The ANALYZE format was originally developed in conjunction
with an image processing system (of the same name) at the Mayo
Foundation.  A common version of the format, although not the most
recent, is called ANALYZE~7.5.  A copy of the file ANALYZE75.pdf has
been included in \pkg{oro.nifti} (accessed via
\code{system.file("doc/ANALYZE75.pdf", package="oro.dicom")}) since it
does not appear to be available from \url{www.mayo.edu} any longer.
An ANALYZE~7.5 format image is comprised of two files, the ``.hdr''
and ``.img'' files, that contain information about the acquisition and
the acquisition itself, respectively.  A more recent adaption of this
format is known as NIfTI-1 and is a product of the Data Format Working
Group (DFWG) from the Neuroimaging Informatics Technology Initiative
(NIfTI; \url{http://nifti.nimh.nih.gov}).  The NIfTI-1 data format is
almost identical to the ANALYZE format, but offers a few improvements
\begin{itemize}
  \item merging of the header and image information
    into one file (.nii)
  \item re-organization of the 348-byte fixed header into more
    relevant categories 
  \item possibility of extending the header information.
\end{itemize}

\subsection{The NIfTI header}
\label{sec:nifti-header}

The NIfTI header inherits its structure (348 bytes in length) from the
ANALYZE data format.  The last four bytes in the NIfTI header
correspond to the ``magic'' field and denote whether or not the header
and image are contained in a single file (\code{magic =
  "n+1\textbackslash{}0"}) or two separate files (\code{magic =
  "ni1\textbackslash{}0"}), the latter being identical to the
structure of the ANALYZE data format.  The NIfTI data format added an
additional four bytes to allow for ``extensions'' to the header.  By
default these four bytes are set to zero.

The first example of reading in, and displaying, medical imaging data
in NIfTI format \texttt{avg152T1\_LR\_nifti.nii.gz} was obtained from
the NIfTI website (\url{http://nifti.nimh.nih.gov/nifti-1/}).
Successful execution of the commands

<<mniLR_nifti>>=
fname <- system.file(file.path("nifti", "mniLR.nii.gz"), package="oro.nifti")
(mniLR <- readNIfTI(fname))
aux.file(mniLR)
descrip(mniLR)
@ 

produces an \proglang{S}4 \code{"nifti"} object (or
\code{"niftiAuditTrail"} if the audit trail option is set).  Two
accessor functions are also provided: \code{aux.file} and
\code{descrip}.  The former is used to access the original name of the
file (if it has been provided) and the latter is the name of a valid
NIfTI header field used to hold a ``description'' (up to 80~characters
in length).

\subsection{The NIfTI image}

Image information begins at the byte position determined by the
\code{voxoffset} slot. In a single NIfTI file (\code{magic =
  "n+1\textbackslash{}0"}), this is by default after the first 352
bytes.  Header extensions extend the size of the header and come
before the image information leading to a consequent increase of
\code{voxoffset} for single NIfTI files.  Split NIfTI files do not
have this problem and \code{voxoffset} is set at 0.

The \code{image} function has been overloaded so that it behaves
differently when dealing with medical image objects (\code{nifti} and
\code{anlz}).  The command

<<mniLR-png,echo=FALSE,results=hide>>=
png(filename="mniLR.png", width=2*480, height=2*480, bg="black")
@ 
<<mniLR-image>>=
image(mniLR)
@ 
<<mniLR-dev.off,echo=FALSE,results=hide>>=
dev.off()
@ 

produces a three-dimensional array of the MNI~brain, with the default
NIfTI axes, and is displayed on a $10{\times}10$ grid of images
(Figure~\ref{fig:mniLR+mniRL}a).  The \code{image} function for
medical image \proglang{S}4 objects is an attempt to balance minimal
user input with enough flexibility to customize the display when
necessary.  For example, single slices may be viewed by using the
option \code{plot.type="single"} in conjuction with the option
\code{z=} to specify the slice.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[tbp]
  \begin{center}
    \begin{tabular}{cc}
      \includegraphics*[width=0.45\textwidth]{mniLR.png} &
      \includegraphics*[width=0.45\textwidth]{mniRL.png}\\
      \textbf{(a)} & \textbf{(b)}
    \end{tabular}
  \end{center}
  \caption{\textbf{(a)} Axial slices of MNI volume \code{mniLR\_nifti}
    stored in the \emph{neurological} convention (right-is-right), but
    displayed in the \emph{radiological} convention (right-is-left).
    \textbf{(b)} Axial slices of MNI volume \code{mniRL\_nifti} stored
    and displayed in the \emph{radiological} convention.}
  \label{fig:mniLR+mniRL}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The second example of reading in and displaying medical imaging data
in the NIfTI format \texttt{avg152T1\_RL\_nifti.nii.gz} was also
obtained from the NIfTI website
(\url{http://nifti.nimh.nih.gov/nifti-1/}).  Successful execution of
the commands

<<mniRL-read>>=
fname <- system.file(file.path("nifti", "mniRL.nii.gz"), package="oro.nifti")
(mniRL <- readNIfTI(fname))
@ 
<<mniRL-png,echo=FALSE,results=hide>>=
png(filename="mniRL.png", width=2*480, height=2*480, bg="black")
@ 
<<mniRL-image>>=
image(mniRL)
<<mniRL-dev.off,echo=FALSE,results=hide>>=
dev.off()
@ 

produces a three-dimensional array of the MNI~brain that is displayed
in a $10{\times}10$ grid of images (Figure~\ref{fig:mniLR+mniRL}b).
The two sets of data in Figure~\ref{fig:mniLR+mniRL} are stored in two
different orientations, commonly referred to as the
\emph{radiological} and \emph{neurological} conventions.  The
neurological convention is where ``right is right'' and one is
essentially looking through the subject.  The radiological convention
is where ``right is left'' and one is looking at the subject.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[tbp]
  \begin{center}
    \includegraphics*[width=0.65\textwidth]{mniRL_orthographic.png}
    \end{center}
  \caption{Orthographic display of the MNI volume \code{mniRL\_nifti}.
    By default the mid-axial, mid-saggital and mid-coronal planes are
    chosen.}
  \label{fig:mniRL-orthographic}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

An additional graphical display function has been added for
\code{nifti} and \code{anlz} objects that allows a so-called
orthographic visualization of the data.

<<mniRL-ortho-png,echo=FALSE,results=hide>>=
png(filename="mniRL_orthographic.png", width=2*480, height=2*480, bg="black")
@ 
<<mniRL-orthographic>>=
orthographic(mniRL)
@ 
<<mniRL-ortho-dev.off,echo=FALSE,results=hide>>=
dev.off()
@ 

As seen in Figure~\ref{fig:mniRL-orthographic} the mid-axial,
mid-saggital and mid-coronal planes are displayed by default.  The
slices used may be set using \code{xyz = c(I,J,K)}, where $(I,J,K)$
are appropriate indices, and the crosshairs will provide a spatial
reference in each plane relative to the other two.

\subsection{A note on axes and orientation}

The NIfTI format contains an implicit generalized spatial
transformation from the data co-ordinate system $(i,j,k)$ into a
real-space ``right-handed'' co-ordinate system.  In this real-space
system, the $(x,y,z)$ axes are \emph{usually} set such that $x$
increases from left to right, $y$ increases from posterior to anterior
and $z$ increases from inferior to superior.

At this point in time the \pkg{oro.nifti} package cannot apply an
arbitrary transform to the imaging data into $(x,y,z)$ space -- such a
transform may require non-integral indices and interpolation steps.
The package does accommodate straightforward transformations of
imaging data; e.g., setting the $i$-axis to increase from right to
left (the neurological convention).  Future versions of
\pkg{oro.nifti} will attempt to address more complicated spatial
transformations and provide functionality to display the $(x,y,z)$
axes on orthographic plots.


\subsection[NIfTI and ANALYZE data in S4]{NIfTI and ANALYZE data in \proglang{S}4}

A major improvement in the \pkg{oro.nifti} package is the fact that
standard medical imaging formats are stored in unique classes under
the \proglang{S}4 system \citep{chambers:2008}.  Essentially, NIfTI
and ANALYZE data are stored as multi-dimensional arrays with extra
slots created that capture the format-specific header information;
e.g., for a \code{nifti} object

<<NIfTI-slots>>=
slotNames(mniRL)
c(mniRL@"cal_min", mniRL@"cal_max")
range(mniRL)
mniRL@"datatype"
convert.datatype(mniRL@"datatype")
@ 

Note, an ANALYZE object has a slightly different set of slots.  Slots
4--47 are taken verbatim from the definition of the NIfTI format and
are read directly from a file.  The slot \code{.Data} is the
multidimensional array (since class \code{nifti} inherits from class
\code{array}) and the slots \code{trail}, \code{extensions} and
\code{reoriented} are used for internal bookkeeping.  In the code
above we have accessed the min/max values of the imaging data using
the \code{"cal_min"} and \code{"cal_max"} slots and matches a direct
interrogation of the \code{.Data} slot using the \code{range}
function.  Looking at the \code{datatype} slot provides a numeric code
that may be converted into a value that indicates the type of byte
structure used (in this case an 8-bit or 1-byte unsigned integer).

As introduced in Section~\ref{sec:nifti-header} there are currently
only two accessor functions to slots in the NIfTI header
(\code{aux.file} and \code{descrip}) -- all other slots are either
ignored or used inside of functions that operate on ANALYZE/NIfTI
objects.  The NIfTI class also has the ability to read and write
extensions that conform to the NIfTI data format.  Customized printing
and validity-checking functions are available to the user and every
attempt has been made to ensure that the information from the
multi-dimensional array is in agreement with the header values.

The constructor function \code{nifti} produces valid NIfTI objects,
including a consistent header, from an arbitrary array.
<<NIfTI-constructor>>=
n <- 100
(random.image <- nifti(array(runif(n*n), c(n,n,1))))
random.image@"dim_"
dim(random.image)
@ 

Data types used for NIfTI formats can be achieved from the
\code{convert.datatype} function.

<<NIfTI-datatypes>>=
cbind(convert.datatype())
@ 

The function \code{writeNIfTI} outputs valid NIfTI class files, which
can be opened in other medical imaging software.  Files can either be
stored as standard \code{.nii} files or compressed with gnuzip
(default).

<<NIfTI-write>>=
writeNIfTI(random.image, "random")
list.files(pattern="random")
@ 

\subsection{The audit trail}

Following on from the \proglang{S}4 implementation of both the NIfTI
and ANALYZE data formats, the ability to extend the NIfTI data format
header is utilized in the \pkg{oro.nifti} package.  First, extensions
are properly handled when reading and writing NIfTI data.  Second,
users are allowed to add extensions to newly-created NIfTI objects by
casting them as \code{niftiExtension} objects and adding
\code{niftiExtensionSection} objects to the \code{extensions} slot.
Third, by default all operations that are performed on a NIfTI object
will generate what we call an \emph{audit trail} that consists of an
\proglang{XML}-based log \citep{XML}.  Each log entry contains
information not only about the function applied to the NIfTI object,
but also various system-level information; e.g., version of
\proglang{R}, user name, date, time, etc.  When writing NIfTI-class
objects to disk, the \proglang{XML}-based NIfTI extension is converted
into plain text and saved using \code{ecode=6} to denote plain ASCII
text only.  The user may control the tracking of data manipulation via
the audit trail using a global option.  For example, please use the
command

<<niftiAuditTrail,eval=FALSE>>=
options(niftiAuditTrail=FALSE)
@

to turn off the ``audit trail'' option in \pkg{oro.nifti}.
Table~\ref{tab:mniLR} displays output from the accessor function
\code{audit.trail(mniLR)}, the \proglang{XML}-based audit trail that
is stored as a NIfTI header extension.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{sidewaystable}
  \caption{\proglang{XML}-based audit trail obtained via
    \code{audit.trail(mniLR)}.}
  \label{tab:mniLR}
  \vspace{3mm}
  \centering
  \begin{tabular}{p{22cm}}
<<NIfTI audit.trail 01>>=
audit.trail(mniLR)
@
  \end{tabular}
\end{sidewaystable}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Interactive visualization}

Basic visualization of \code{nifti} and \code{anlz} class images can
be achieved with any visualization for arrays in \proglang{R}.  For
example, the \pkg{EBImage} package provides functions \code{display}
and \code{animate} for visualization \citep{EBImage}.  Please note
that functions in \pkg{EBImage} expect greyscale values in the range
$[0,1]$, hence the display of \code{nifti} data may be performed using

<<EBImage01,eval=FALSE>>=
mniLR.range <- range(mniLR)
display((mniLR - min(mniLR)) / diff(mniLR.range))
@

Interactive visualization of multi-dimensional arrays, stored in NIfTI
or ANALYZE format, is however best performed outside of \proglang{R}
at this point in time.  Popular viewers, especially for neuroimaging
data, are
\begin{itemize}
\item FSLView (\url{http://www.fmrib.ox.ac.uk/fsl/fslview/}),
\item MRIcron (\url{http://cabiatl.com/mricron/}).
\end{itemize}
The \pkg{mritc} package provides basic interactive visualization of
ANALYZE/NIfTI data using a \proglang{Tcl/Tk} interface \citep{mritc}.

\subsection{An example using functional MRI data} % from the NIfTI-1 DFWG}

%\subsubsection{Simple time-series or multi-volume images}

This is an example of reading in, and displaying, a four-dimensional
medical imaging data set in NIfTI format \texttt{filtered\_func\_data}
obtained \textcolor{BrickRed}{from the FSL evaluation and example data
  suite (\url{http://www.fmrib.ox.ac.uk/fsl/fsl/feeds.html}).}
Successful execution of the commands

<<ffd>>=
(ffd <- readNIfTI("filtered_func_data"))
@ 
<<ffd-png,echo=FALSE,results=hide>>=
png(filename="ffd.png", width=2*480, height=2*480, bg="black")
@ 
<<ffd-image>>=
image(ffd, zlim=range(ffd))
@ 
<<ffd-dev.off,echo=FALSE,results=hide>>=
dev.off()
@ 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[tbp]
  \begin{center}
    \begin{tabular}{c}
      \includegraphics*[width=0.6\textwidth]{ffd.png}\\
      \textbf{(a)}\\
      \includegraphics*[width=0.6\textwidth]{ffd_orthographic.png}\\
      \textbf{(b)}
    \end{tabular}
  \end{center}
  \caption{\textbf{(a)} Axial slices of the functional MRI data set
    \code{filtered\_func\_data} from the first acquisition.
    \textbf{(b)} Orthographic display of the first volume from the
    functional MRI data set \texttt{filtered\_func\_data}.}
  \label{fig:ffd+orthographic}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

produces a four-dimensional (4D) array of imaging data that may be
displayed in a $5{\times}5$ grid of images
(Figure~\ref{fig:ffd+orthographic}a).  The first three dimensions are
spatial locations of the voxel (volume element) and the fourth
dimension is time for this functional MRI (fMRI) acquisition.  As seen
from the summary of object, there are 21~axial slices of fairly coarse
resolution ($4{\times}4{\times}6\;\text{mm}$) and reasonable temporal
resolution ($3\;\text{s}$).  Figure~\ref{fig:ffd+orthographic}b
depicts the orthographic display of the \texttt{filtered\_func\_data}
using the axial plane \textcolor{BrickRed}{containing the
  left-and-right thalamus to approximately center the crosshair
  vertically}.

<<ffd-ortho-png,echo=FALSE,results=hide>>=
png(filename="ffd_orthographic.png", width=2*480, height=2*480, bg="black")
@ 
<<ffd-orthographic>>=
orthographic(ffd, xyz=c(34,29,10))
@ 
<<ffd-ortho-dev.off,echo=FALSE,results=hide>>=
dev.off()
@ 

\subsubsection{Statistical analysis}

\textcolor{BrickRed}{The \proglang{R} programming environment provides
  a wide variety of statistical methodology for the quantitative
  analysis of medical imaging data.  For example, functionl MRI (fMRI)
  data are typically analysed by applying a multiple linear regression
  model, commonly referred to in the literature as a general linear
  model (GLM), that utilizes the stimulus experiment to construct the
  design matrix.  Estimation of the regression coefficients in the GLM
  produces a statistical image; e.g., $Z$-statistics for a voxel-wise
  hypothesis test on activation in fMRI experiments
  \citep{fri-etal:spms,fri-etal:revisited}.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[tbp]
  \begin{center}
    \includegraphics*[width=\textwidth]{ffd_design.pdf}
    \end{center}
  \caption{Visual (30 seconds on/off) and auditory (45 seconds on/off)
    stimuli, convolved with a parametric haemodynamic response
    function, used in the GLM-based fMRI analysis.}
  \label{fig:ffd-design}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textcolor{BrickRed}{The 4D volume of imaging data in
  \texttt{filtered\_func\_data} was acquired in an experiment with a
  repetition time $\text{TR}=3\;\text{s}$, using both visual and
  auditory stimuli.  The visual stimulus was applied using an on/off
  pattern for a duration of 60~seconds and the auditory stimulus was
  applied using an on/off pattern for a duration of 90~seconds.  A
  parametric haemodynamic respone function (HRF), with mean $\mu=6$
  and standard deviation $\sigma=3$, is utilized here which is similar
  to the default values in FSL \citep{smi-etal:FSL}.  We construct the
  experimental design and HRF in seconds, perform the convolution and
  then downsample by a factor of three in order to obtain columns of
  the design matrix that match the acquisition of the MRI data.}

<<ffd-glm-design,echo=TRUE,results=hide>>=
## visual (30s on/off) and auditory (45s on/off) stimulus
#visual <- rep(c(-0.5,0.5), each=30, times=12)
#auditory <- rep(c(-0.5,0.5), each=45, times=12)
## haemodynamic response function with mean=6 and sd=3
#hrf <- c(dgamma(1:15, 4, scale=1.5))
## convolve stimuli with hrf
#visual.hrf <- auditory.hrf <- rep(NA, 540)
#for (k in 60:599) {
#  visual.hrf[k-59] <- sum(visual[k-(1:15)] * hrf)
#}
#for (k in 90:629) {
#  auditory.hrf[k-89] <- sum(auditory[k-(1:15)] * hrf)
#}
## add phase
#visual.hrf <- c(rep(0.5, 30), visual.hrf)
#auditory.hrf <- c(rep(0.5, 45), auditory.hrf)
## TR = 3s
#index <- seq(3, 540, by=3)
#visual.hrf2 <- visual.hrf[index] - mean(visual.hrf[index]) # center
#auditory.hrf2 <- auditory.hrf[index] - mean(auditory.hrf[index]) # center
## visual (30s on/off)
visual <- rep(c(-0.5,0.5), each=30, times=9)
## auditory (45s on/off) stimulus
auditory <- rep(c(-0.5,0.5), each=45, times=6)
## haemodynamic response function with mean=6 and sd=3
hrf <- c(dgamma(1:15, 4, scale=1.5))
## convolve visual stimulus with HRF
hrf0 <- c(hrf, rep(0, length(visual)-length(hrf)))
visual.hrf <- convolve(hrf0, visual)
## convolve auditory stimulus with HRF
hrf0 <- c(hrf, rep(0, length(auditory)-length(hrf)))
auditory.hrf <- convolve(hrf0, auditory)
index <- seq(3, 540, by=3)
visual.hrf <- visual.hrf[index] # - mean(visual.hrf[index]) # center
auditory.hrf <- auditory.hrf[index] # - mean(auditory.hrf[index]) # center
@ 
<<ffd-design.png,echo=FALSE,results=hide>>=
pdf("ffd_design.pdf", width=10, height=5)
par(mfrow=c(1,2), mex=0.85)
plot(index, visual.hrf, type="l", 
     xlab="Acquisition Index", ylab="Visual Stimulus")
plot(index, auditory.hrf, type="l", 
     xlab="Acquisition Index", ylab="Auditory Stimulus") 
dev.off()
@ 

\textcolor{BrickRed}{Figure~\ref{fig:ffd-design} depicts the visual
  and auditory stimuli, convolved with the HRF, in the order of
  acquisition.  The design matrix is than used in a voxel-wise GLM,
  where the \code{lsfit} function in \proglang{R} estimates the
  parameters in the linear regression.  At each voxel $t$-statistics
  and their associated $p$-values are computed for the hypothesis test
  of no effect for each individual stimulus, along with an
  $F$-statistic for the hypothesis test of no effect of any stimuli
  using the \code{ls.print} function.}

<<ffd-glm,echo=TRUE,results=hide>>=
## background threshold: 10% max intensity
voxel.lsfit <- function(x, thresh) { # general linear model
  ## check against background threshold
  if (max(x) < thresh) {
    return(rep(NA, 5))
  }
  ## glm
  ## output <- lm(x ~ visual.hrf + auditory.hrf)
  output <- lsfit(cbind(visual.hrf, auditory.hrf), x)
  ## extract t-statistic, p-values
  ## c(as.vector(summary(output)$coeff[2:3,3:4]), summary(output)$fstatistic[1])
  output.t <- ls.print(output, print.it=FALSE)$coef.table[[1]][2:3,3:4]
  output.f <- ls.print(output, print.it=FALSE)$summary[3]
  c(output.t, as.numeric(output.f))
  ## as.vector(output.t)
}
## apply local glm to each voxel
ffd.glm <- apply(ffd, 1:3, voxel.lsfit, thresh=0.1 * max(ffd))
@ 

\textcolor{BrickRed}{Given the multidimensional array of output from
  the GLM fitting procedure, the $t$-statistics are separated and
  converted into $Z$-statistics to follow the convention used in FSL.
  For the purposes of this example we have not applied any multiple
  comparisons correction procedure and, instead, use a relatively
  large threshold of $Z>5$ for visualization.}

<<zstat1>>=
## t-statistics
##t.visual <- nifti(ffd.glm[1,,,], datatype=16)
##t.auditory <- nifti(ffd.glm[2,,,], datatype=16)
## p-values
#p.visual <- nifti(ffd.glm[3,,,], datatype=16)
#p.auditoy <- nifti(ffd.glm[4,,,], datatype=16)
## F-statistics
#F <- nifti(ffd.glm[5,,,], datatype=16)
# Z-statistic: normalized t-statistic
dof <- ntim(ffd) - 1
Z.visual <- nifti(qnorm(pt(ffd.glm[1,,,], dof, log.p=TRUE), log.p=TRUE),
                  datatype=16)
Z.auditory <- nifti(qnorm(pt(ffd.glm[2,,,], dof, log.p=TRUE), log.p=TRUE),
                    datatype=16)
@ 
<<zstat1-png,echo=FALSE,results=hide>>=
png("ffd_zstat1.png", width=2*480, height=2*480, bg="black")
@ 
<<zstat1-overlay>>=
overlay(ffd, ifelse(Z.visual > 5, Z.visual, NA), 
        zlim.x=range(ffd), zlim.y=range(Z.visual, na.rm=TRUE))
<<zstat1-dev.off,echo=FALSE,results=hide>>=
dev.off()
@ 
<<zstat2-png,echo=FALSE,results=hide>>=
png("ffd_zstat2.png", width=2*480, height=2*480, bg="black")
@ 
<<zstst2-overlay>>=
overlay(ffd, ifelse(Z.auditory > 5, Z.auditory, NA), 
        zlim.x=range(ffd), zlim.y=range(Z.auditory, na.rm=TRUE))
<<zstat2-dev.off,echo=FALSE,results=hide>>=
dev.off()
@ 

\textcolor{BrickRed}{Statistical images in neuroimaging are commonly
  displayed as an overlay on top of a reference image (one of the
  dynamic acquisitions) in order to provide anatomical context.  The
  \code{overlay} command in \pkg{oro.nifti} allows one to display the
  statistical image of voxel-wise activations overlayed on one of the
  original EPI (echo planar imaging) volumes acquired in the fMRI
  experiment.  The 3D array of $Z$-statistics for the visual and
  auditory tasks are overlayed on the original data for ``anatomical''
  reference in Figure~\ref{fig:zstat1+zstat2}.  The $Z$-statistics
  that exceed the threshold appear to match know neuroanatomy, where
  the visual cortex in the occipital lobe shows activiation under the
  visual stimulus (Figure~\ref{fig:zstat1+zstat2}a) and the primary
  auditory cortex in the temporal lobe shows activation under the
  auditory stimulus (Figure~\ref{fig:zstat1+zstat2}b).}
% The function \code{overlay} extends the capabilities of displaying
% two-dimensional images by allowing one to add a statistical image to
% a reference image of the same dimension.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[p]
  \begin{center}
    \begin{tabular}{c}
      \includegraphics*[width=0.6\textwidth]{ffd_zstat1.png}\\
      \textbf{(a)}\\
      \includegraphics*[width=0.6\textwidth]{ffd_zstat2.png}\\
      \textbf{(b)}
    \end{tabular}
  \end{center}
  \caption{\textbf{(a)} Axial slices of the functional MRI data with
    the statistical image from the visual stimulus overlayed.
    \textbf{(b)} Axial slices of the functional MRI data with the
    statistical image from the auditory stimulus overlayed.  Both sets
    of test statistics were thresholded at $Z\geq{5}$ for all voxel.}
  \label{fig:zstat1+zstat2}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Converting DICOM to NIfTI}
\label{sec:dicom2nifti}

The \pkg{oro.dicom} and \pkg{oro.nifti} packages have been
specifically designed to use as much information as possible from the
metadata-rich DICOM format and apply that information in the
construction of the NIfTI data volume.  The function
\code{dicom2nifti} converts a list of DICOM images into an
\code{nifti} object, and likewise \code{dicom2analyze} converts such a
list into an \code{anlz} object.

Historically, data conversion from DICOM to NIfTI (or ANALYZE) has
been provided outside of \proglang{R} using one of several standalone
software packages:
\begin{itemize}
\item Xmedcon \citep{xmedcon}, 
\item FreeSurfer (\url{http://surfer.nmr.mgh.harvard.edu}),
\item MRIConvert (\url{http://lnci.oregon.edu/\~jolinda/MRIConvert}).
\end{itemize}
This is by no means an exhaustive list of software packages available
for DICOM conversion.  In addition there are several other 
\proglang{R} packages with the ability to process DICOM data
\begin{itemize}
\item \pkg{fmri} \citep{pol-tab:fmri},
\item \pkg{tractor.base} \citep{tractor.base} (part of the tractor
  project \url{http://code.google.com/p/tractor}).
\end{itemize}

\subsection{An example using a single-series data set}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[p]
  \begin{center}
    \begin{tabular}{c}
    \includegraphics*[width=0.6\textwidth]{hk40n_image.png}\\
    \textbf{(a)}\\
    \includegraphics*[width=0.6\textwidth]{hk40n_orthographic.png}\\
    \textbf{(b)}
    \end{tabular}
  \end{center}
  \caption{\textbf{(a)} Lightbox display of three-dimensional array of
    images.  \textbf{(b)} Orthographic display of the same
    three-dimensional array (using the default settings for
    \code{orthographic}).}
  \label{fig:hk40n}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Using the 40~images from the \code{hk40} object (previously defined in
Section~\ref{sec:dicom-header}) it is straightforward to perform
DICOM-to-NIfTI conversion using only default settings and plot the
results in either lightbox or orthographic displays.

<<DICOM2NIFTI HK40 01>>=
dput(formals(dicom2nifti))
(hk40n <- dicom2nifti(hk40))
@ 
<<DICOM2NIFTI HK40 02,eval=FALSE>>=
image(hk40n)
orthographic(hk40n)
@ 
<<DICOM2NIFTI HK40 03,echo=FALSE,results=hide>>=
png("hk40n_image.png", width=2*480, height=2*480, bg="black")
image(hk40n)
dev.off()
png("hk40n_orthographic.png", width=2*480, height=2*480, bg="black")
orthographic(hk40n)
dev.off()
@ 

At default \code{dicom2nifti} takes all image data from the DICOM list
and creates a 3D image.  Four-dimensional image volumes (three in
space plus one in time) are also converted automatically by specifying
\code{DIM=4}, where slice positions are taken from the
\texttt{ImagePositionPatient} DICOM header field.  For example, using
\code{DIM=4} on the \code{hk40} DICOM data,

<<DICOM2NIFTI HK40 04>>=
(hk40n <- dicom2nifti(hk40, DIM=4))
@ 

will also produce a three-dimensional volume of images, since the
\texttt{ImagePositionPatient} field is unique for each single slice of
the volume.

The functions \code{dicom2nifti} and \code{dicom2analyze} will fail
when the dimensions of the individual images in the DICOM list do not
match.  However, they do not check for different series numbers or
patient~IDs so caution should be exercised when scripting automated
workflows for DICOM-to-NIfTI conversion.  In cases where a DICOM file
includes images from more than one series, the corresponding slices
have to be chosen before conversion, using \code{dicomTable},
\code{extractHeader}, and \code{matchHeader}.

\subsection{An example using a multiple-volume data set}

The National Biomedical Imaging Archive (NBIA) is a searchable,
national repository integrating \emph{in vivo} cancer images with
clinical and genomic data.  The NBIA provides the scientific community
with public access to DICOM images, image markup, annotations, and
rich metadata.\footnote{\url{http://cabig.nci.nih.gov/tools/NCIA}} The
multiple MRI sequences processed here were downloaded from the
``RIDER~Neuro~MRI''
collection.\footnote{\url{http://wiki.nci.nih.gov/display/CIP/RIDER}}
A small \code{for} loop has been written to operate on a subset of the
DICOM directory structure, where the \code{SeriesInstanceUID} DICOM
header field is assumed to be 100\% accurate in series
differentiation.

<<RIDER Neuro MRI>>=
subject <- "1086100996"
DCM <- dicomSeparate(subject, verbose=TRUE, counter=100)
seriesInstanceUID <- extractHeader(DCM$hdr, "SeriesInstanceUID", FALSE)
for (uid in unique(seriesInstanceUID)) {
  index <- which(unlist(lapply(DCM$hdr, function(x) uid %in% x$value)))
  uid.dcm <- list(hdr=DCM$hdr[index], img=DCM$img[index])
  patientsName <- extractHeader(uid.dcm$hdr, "PatientsName", FALSE)
  studyDate <- extractHeader(uid.dcm$hdr, "StudyDate", FALSE)
  seriesDescription <- extractHeader(uid.dcm$hdr, "SeriesDescription", FALSE)
  fname <- paste(gsub("[^0-9A-Za-z]", "", 
                      unique(c(patientsName, studyDate, seriesDescription))), 
                 collapse="_")
  cat("##  ", fname, fill=TRUE)
  if (gsub("[^0-9A-Za-z]", "", unique(seriesDescription)) == "axtensor") {
    D <- 4
    reslice <- FALSE
  } else {
    D <- 3
    reslice <- TRUE
  }
  uid.nifti <- dicom2nifti(uid.dcm, DIM=D, reslice=reslice,
                           descrip=c("PatientID", "SeriesDescription"))
  writeNIfTI(uid.nifti, fname)
}
@ 

Note, the diffusion tensor imaging (DTI) data \code{axtensor} is
assumed to be four dimensional and all other series (the multiple
flip-angle acquisitions) are assumed to be three dimensional.  There
is always a balance between what information should be pre-specified
versus what can easily be extracted from the DICOM headers or images.

\section{Conclusion}

Medical image analysis depends on the efficient manipulation and
conversion of DICOM data.  The \pkg{oro.dicom} and \pkg{oro.nifti}
packages have been developed to provide the user with a set of
functions that mask as many of the background details as possible
while still providing flexible and robust performance.  

The future of medical image analysis in \proglang{R} will benefit from
a unified view of the imaging data standards: DICOM, NIfTI and
ANALYZE.  The existence of a single package for handling imaging data
formats would facilitate interoperability between the ever increasing
number of \proglang{R} packages devoted to medical image analysis.  We
do not assume that the data structures in \pkg{oro.dicom} or
\pkg{oro.nifti} are best-suited for this purpose and we welcome an
open discussion around how best to provide this standardization to the
end user.

\section*{Acknowledgments}

The authors would like to thank the National Biomedical Imaging
Archive (NBIA), the National Cancer Institute (NCI), the National
Institute of Health (NIH) and all institutions that have contributed
medical imaging data to the public domain.  VS is supported
by the LMU innovative project BioMed-S: Analysis and Modelling of
Complex Systems.

\bibliography{dicom_nifti}

\end{document}
